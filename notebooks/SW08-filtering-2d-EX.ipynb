{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Filtering 2D**\n",
    "\n",
    "<div style=\"color:#777777;margin-top: -15px;\">\n",
    "<b>Author</b>: Norman Juchler |\n",
    "<b>Course</b>: ADLS ISP |\n",
    "<b>Version</b>: v1.2 <br><br>\n",
    "<!-- v1.2, 12.04.2025: Refactored text -->\n",
    "</div>\n",
    "\n",
    "In this notebook, we will explore image filtering in both the spatial and frequency domains. We will also examine the concept of convolution and its role in image processing.\n",
    "\n",
    "<!--\n",
    "## **Exercises**\n",
    "* [Exercise 1: Spectral filtering](#exercise1)  \n",
    "* [Exercise 2: Interpretation of spectra](#exercise2)  \n",
    "* [Exercise 3: Spatial filtering with kernels](#exercise3)  \n",
    "* [Exercise 4: Edge detection](#exercise4)  \n",
    "* [Exercise 5: Border handling](#exercise5)\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Preparations**\n",
    "\n",
    "The usual preparations... Before we begin, let's load some drawing functions for rendering images effortlessly in this Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.fft\n",
    "import scipy.signal\n",
    "\n",
    "# Enable vectorized output (for nicer plots)\n",
    "%config InlineBackend.figure_formats = [\"svg\"]\n",
    "\n",
    "# Inline backend configuration\n",
    "%matplotlib inline\n",
    "\n",
    "# Functionality related to this course\n",
    "sys.path.append(\"..\")\n",
    "import isp\n",
    "\n",
    "# Jupyter / IPython configuration:\n",
    "# Automatically reload modules when modified\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='exercise1'></a>\n",
    "\n",
    "## **â˜† Exercise 1: Spectral filtering**\n",
    "\n",
    "The photo *\"moon-walk.jpg\"* shows astronaut Harrison Schmitt walking on the Moon during the Apollo 17 mission in 1972. This image has been artificially distorted with periodic noise. If you're curious, the code used to generate the distortion is provided below in the *Supplemental Material* section. The goal of this exercise is to remove the distortion using spectral filtering.\n",
    "\n",
    "Such regular, periodic distortions were common in the early days of digital printing, particularly when using the [halftone technique](https://en.wikipedia.org/wiki/Halftone). This method simulates continuous-tone imagery (i.e., images with smooth intensity gradients) by varying the size or spacing of dots, which can introduce visible, repetitive patterns in printed images.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Original: moon-walk.jpg                   |  moon-walk-distorted-w2.5.jpg         | moon-walk-distorted-w5.jpg \n",
    ":-------------------------:|:-------------------------:|:-------------------------:\n",
    "![](../data/images/moon-walk-square.jpg)  | ![](../data/images/moon-walk-distorted-w2.5.jpg)  |  ![](../data/images/moon-walk-distorted-w5.jpg) | \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### **Instructions**\n",
    "\n",
    "1. Load the images \"moon-walk-distorted-w5.jpg\" and \"moon-walk-distorted-w2.5.jpg\" from the folder \"../data/images/\" and display them.\n",
    "2. Compute the Fourier transform of the images and display both the magnitude and phase.\n",
    "3. From the subfolder \"../data/images/moon-walk-masks/\", load and test different filter masks for spectral filtering.\n",
    "4. Apply the masks to the Fourier transform to suppress the frequency components responsible for the noise.\n",
    "5. Compute the inverse Fourier transform to reconstruct the filtered image.\n",
    "6. Repeat the process using different masks and for other distortion levels (e.g., w5, w7.5).\n",
    "7. Discuss your results and reflect on the effectiveness of the filtering.\n",
    "\n",
    "**Note:** Using the code provided in the *Supplemental Material* section below, you can generate distorted images with varying levels of distortion. The parameter `w` defines the *spatial period* (i.e., the wavelength in pixels) of the distortion pattern. For example, the image `moon-walk-distorted-w5.jpg` was distorted using a pattern with a spatial period of `w = 5`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "###    EXERCISE    ###\n",
    "######################\n",
    "\n",
    "# 1) Load the image \"moon-walk-distorted-w2.5.jpg\" and display it.\n",
    "#    (...or moon-walk-distorted-w5.jpg, or moon-walk-distorted-w7.5.jpg)\n",
    "img = ...\n",
    "isp.show_image(img)\n",
    "                \n",
    "# 2) Compute the Fourier transform and display the magnitude / phase.\n",
    "ft = ...\n",
    "ft_amp = ...\n",
    "ft_phase = ...\n",
    "\n",
    "isp.show_image_pair(ft_amp, ft_phase, \n",
    "                    title1=\"Amplitude spectrum\", \n",
    "                    title2=\"Phase spectrum\", \n",
    "                    normalize=True)\n",
    "\n",
    "# 3) Load a filter mask of the subfolder ../data/images/moon-walk-masks/\n",
    "mask = ...\n",
    "isp.show_image(mask)\n",
    "\n",
    "# 4) Apply the mask to the Fourier transform \n",
    "ft_filt = ...\n",
    "\n",
    "# 5) Compute the inverse Fourier transform and display the result\n",
    "img_filt = ...\n",
    "isp.show_image(img_filt)\n",
    "\n",
    "# 6) Repeat the process for other masks and distortion levels (w=5, w=7.5)\n",
    "# 7) Discuss the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ***Supplemental Materials: Code to Generate Distorted Images and Filter Masks***\n",
    "\n",
    "**<u>Feel free to skip this section if you're not interested in the implementation details.</u> ðŸ™‚**\n",
    "\n",
    "The distorted images were generated using the code below. You can use it to create your own distorted versions. The distortion is based on the superposition of multiple gratings at different orientations. Key parameters include the *wavelength* of the gratings (in pixels) and the *angular step size* that defines their orientation. For this exercise, distortions were generated using wavelengths of 2.5, 5.0, and 7.5 pixels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinusoidal_grating_dir(shape, A, l, phi=0, angle=0, offset=0):\n",
    "    \"\"\"This is the sinusoidal grating function that we already have implemented\n",
    "    in the previous notebook. It generates a sinusoidal grating image with the\n",
    "    specified parameters.\n",
    "    \"\"\"\n",
    "    i = np.arange(shape[1])\n",
    "    j = np.arange(shape[0])\n",
    "    X, Y = np.meshgrid(i, j)\n",
    "    angle = np.deg2rad(angle)\n",
    "    img = A * np.sin(2 * np.pi / l * ((X*np.cos(angle) + Y*np.sin(angle))) + phi) + offset\n",
    "    return img.astype(np.float32)\n",
    "\n",
    "\n",
    "def add_periodic_pattern(image, wavelength, step, alpha=0.6):\n",
    "    # Convert to floating point and normalize\n",
    "    if image.dtype == np.uint8:\n",
    "        image = image.astype(np.float32)\n",
    "        image /= 255\n",
    "\n",
    "    # Add distortion: sinusoidal gratings a different orientations:\n",
    "    #    angles = [0, 30, 60, 90, 120, 150]\n",
    "    # Note: We only need angles from 0 to 180, since the gratings are symmetric.\n",
    "    #       The gratings at 0 and 180 degrees are mirrored, and will cancel each \n",
    "    #       other out.\n",
    "\n",
    "    # Parameters for the sinusoidal gratings\n",
    "    amplitude = 1\n",
    "    phase = 0\n",
    "    angles = np.arange(0, 180, step)\n",
    "    # Create a list of gratings\n",
    "    gratings = [sinusoidal_grating_dir(shape=(image.shape), \n",
    "                                       A=amplitude, \n",
    "                                       l=wavelength, \n",
    "                                       phi=phase, \n",
    "                                       angle=angle, \n",
    "                                       offset=0) for angle in angles]\n",
    "    # Sum the list of images element-wise (using numpy)\n",
    "    gratings = np.sum(gratings, axis=0)\n",
    "    # Normalize (floating point image, values between 0 and 1)\n",
    "    gratings = (gratings - gratings.min()) / (gratings.max() - gratings.min())\n",
    "    # Mix the gratings with the original image\n",
    "    image = (1-alpha)*image + alpha*gratings\n",
    "    return image\n",
    "\n",
    "\n",
    "# Parameters for the sinusoidal gratings:\n",
    "wavelength = 5    # Wavelegth of the grating (in pixels, here: 2.5, 5, 7.5)\n",
    "step = 30         # Step size for the angles (in degrees)\n",
    "\n",
    "# Load the image\n",
    "image = cv.imread(\"../data/images/moon-walk-square.jpg\", cv.IMREAD_GRAYSCALE)\n",
    "image = add_periodic_pattern(image, wavelength, step)\n",
    "isp.show_image(image, normalize=True);\n",
    "\n",
    "# cv.imwrite(\"../data/images/moon-walk-distorted-w%g.jpg\" % wavelength, \n",
    "#            image*255, [int(cv.IMWRITE_JPEG_QUALITY), 90]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- \n",
    "Development note: \n",
    "\n",
    "```python\n",
    "# Force the input image to have a suitable size in order to avoid edge \n",
    "# effects when calculating the DFT/IDFT. See this post for details:\n",
    "# https://dsp.stackexchange.com/questions/93712/\n",
    "h = cv.getOptimalDFTSize(image.shape[0])\n",
    "w = cv.getOptimalDFTSize(image.shape[1])\n",
    "mt = (w - image.shape[1]) // 2\n",
    "mb = (w - image.shape[1] - mt)\n",
    "ml = (h - image.shape[0]) // 2\n",
    "mr = (h - image.shape[0] - ml)\n",
    "image = cv.copyMakeBorder(image, mt, mb, ml, mr, cv.BORDER_REFLECT)\n",
    "cv.imwrite(\"../data/images/moon-walk-square-fixed.jpg\", \n",
    "           image, [int(cv.IMWRITE_JPEG_QUALITY), 90]);\n",
    "```\n",
    "-->\n",
    "\n",
    "Create the different masks. The mask geometries depend on the wavelength (and the angle step) of the periodic distortion created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circular_mask_pattern(image, wavelength, step, size):\n",
    "    \"\"\"Function that creates a mask with small circles along a bigger circle. \n",
    "    The circle radii are determined by the wavelength parameter.\"\"\"\n",
    "    mask = np.zeros_like(image)\n",
    "    radius = image.shape[0]/wavelength\n",
    "    angles = np.arange(0, 360, step)\n",
    "    for a in angles:\n",
    "        x = int(image.shape[1]/2 + radius*np.cos(np.deg2rad(a)))\n",
    "        y = int(image.shape[0]/2 + radius*np.sin(np.deg2rad(a)))\n",
    "        mask = cv.circle(mask, (x, y), size, 1, -1)\n",
    "    mask = 1-mask\n",
    "    return mask\n",
    "\n",
    "# Ensure output folder\n",
    "isp.ensure_dir(\"../data/images/moon-walk-masks/\")\n",
    "\n",
    "# Used for the ring masks\n",
    "J, I = np.meshgrid(np.arange(image.shape[1]), np.arange(image.shape[0]))\n",
    "R = np.sqrt((J - image.shape[1]//2)**2 + (I - image.shape[0]//2)**2)\n",
    "\n",
    "# Mask 1: Low-pass filter\n",
    "margin = 15\n",
    "mask_low = np.zeros_like(image, dtype=np.uint8)\n",
    "mask_low[R < (image.shape[0]/wavelength-margin)] = 1\n",
    "cv.imwrite(\"../data/images/moon-walk-masks/mask1-w%g.png\" % wavelength, \n",
    "           (mask_low*255).astype(np.uint8))\n",
    "\n",
    "# Mask 2: High-pass filter\n",
    "mask_high = np.zeros_like(image, dtype=np.uint8)\n",
    "mask_high[R > (image.shape[0]/wavelength-margin)] = 1\n",
    "cv.imwrite(\"../data/images/moon-walk-masks/mask2-w%g.png\" % wavelength, \n",
    "           (mask_high*255).astype(np.uint8))\n",
    "\n",
    "# Mask 3: Circular mask\n",
    "size = 9\n",
    "mask = circular_mask_pattern(image, wavelength, step, size=size)\n",
    "mask_circ_hs = mask.copy()\n",
    "cv.imwrite(\"../data/images/moon-walk-masks/mask3-w%g.png\" % wavelength, \n",
    "           (mask_circ_hs*255).astype(np.uint8))\n",
    "\n",
    "# Mask 4: Linearly weighted circular mask\n",
    "# Apply distance transform to the circular mask\n",
    "mask = circular_mask_pattern(image, wavelength, step, size=size*2)\n",
    "dist = cv.distanceTransform(1-mask.astype(np.uint8), cv.DIST_L2, cv.DIST_MASK_PRECISE)\n",
    "mask_circ_lin = (1-dist/np.max(dist))\n",
    "cv.imwrite(\"../data/images/moon-walk-masks/mask4-w%g.png\" % wavelength, \n",
    "           (mask_circ_lin*255).astype(np.uint8))\n",
    "\n",
    "# Mask 5: Gaussian weighted circular mask\n",
    "# Distance --> Gaussian values\n",
    "dist = np.exp(-dist**2/(size**2))\n",
    "mask = dist/np.max(dist)\n",
    "mask_circ_gauss = (mask-mask.min())/(np.max(mask)-mask.min())\n",
    "cv.imwrite(\"../data/images/moon-walk-masks/mask5-w%g.png\" % wavelength, \n",
    "           (mask_circ_gauss*255).astype(np.uint8))\n",
    "\n",
    "# Mask 6: Ring mask\n",
    "radius = image.shape[0]/wavelength\n",
    "dist = np.abs(R - radius)\n",
    "mask_ring_hs = dist>size\n",
    "cv.imwrite(\"../data/images/moon-walk-masks/mask6-w%g.png\" % wavelength,\n",
    "           (mask_ring_hs*255).astype(np.uint8))\n",
    "\n",
    "# Mask 7: Linearly weighted ring mask\n",
    "dist = np.clip(dist, 0, size)\n",
    "mask_ring_lin = dist.astype(float) / size\n",
    "cv.imwrite(\"../data/images/moon-walk-masks/mask7-w%g.png\" % wavelength, \n",
    "           (mask_ring_lin*255).astype(np.uint8))\n",
    "\n",
    "# Mask 8: Gaussian weighted ring mask\n",
    "mask = np.exp(-dist**2/(size**2))\n",
    "mask = (mask-mask.min())/(np.max(mask)-mask.min())\n",
    "mask_ring_gauss = (1-mask)\n",
    "cv.imwrite(\"../data/images/moon-walk-masks/mask8-w%g.png\" % wavelength, \n",
    "           (mask_ring_gauss*255).astype(np.uint8))\n",
    "\n",
    "# Test mask, pick one of the above masks:\n",
    "#   - mask_low\n",
    "#   - mask_high\n",
    "#   - mask_circ_hs\n",
    "#   - mask_circ_lin\n",
    "#   - mask_circ_gauss\n",
    "#   - mask_ring_hs\n",
    "#   - mask_ring_lin\n",
    "#   - mask_ring_gauss\n",
    "mask = mask_ring_gauss\n",
    "ft = scipy.fft.fft2(image)\n",
    "ft = scipy.fft.fftshift(ft)\n",
    "ft_amp = np.log(np.abs(ft))\n",
    "ft_amp *= mask\n",
    "isp.show_image_pair(mask, ft_amp, \n",
    "                    title1=\"Mask\", \n",
    "                    title2=\"Amplitude spectrum\", \n",
    "                    figsize=(9, 5),\n",
    "                    normalize=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='exercise2'></a>\n",
    "\n",
    "## **â˜† Exercise 2: Interpretation of spectra**\n",
    "\n",
    "Take a look at the amplitude spectrum of the image below, which displays a honeycomb pattern.\n",
    "\n",
    "![Honeycomb](../data/images/honeycomb1.jpg)\n",
    "\n",
    "\n",
    "### **Instructions**\n",
    "\n",
    "Recall that the Fourier transform is generally complex-valued. This means that each element in the Fourier transform (an NxM array) is a complex number, which can be uniquely described by its magnitude $|z|$ and phase $\\varphi = \\arg(z)$: $\\quad z = |z| e^{i\\varphi} $\n",
    "\n",
    "1. Load the image honeycomb1.jpg (or honeycomb2.jpg) in grayscale.\n",
    "2. Compute and visualize the amplitude and phase spectra.\n",
    "3. Answer: What information can you extract from the amplitude and phase spectra of the image?\n",
    "4. Reconstruct the image from its Fourier transform by:\n",
    "   * Setting the amplitude to 1 (i.e., keep only the phase information, using a constant amplitude)\n",
    "   * Setting the phase to 0 (i.e., keep only the amplitude, remove phase information)\n",
    "5. Reflect: What can you infer from these reconstructions?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "###    EXERCISE    ###\n",
    "######################\n",
    "\n",
    "# 1) Load the honeycomb image \"honeycomb1.jpg\" (or \"honeycomb2.jpg\") \n",
    "image = ...\n",
    "\n",
    "# 2) Display the image and its Fourier transform (magnitude and phase)\n",
    "ft = ...\n",
    "ft_amp = ...\n",
    "ft_phase = ...\n",
    "\n",
    "# Display the spectra using our convenience function isp.show_image()\n",
    "# (The argument \"normalize stretch\" is used to enhance the spectrum of the \n",
    "# spectra to see more structure). Alternatively, just use normalize=True\n",
    "isp.show_image_chain([image, ft_amp, ft_phase], normalize_stretch=0.1);\n",
    "\n",
    "# 3) Question: What can be seen in the Fourier transform?\n",
    "...\n",
    "\n",
    "# 4) Reconstruct the image from the Fourier transform and display it\n",
    "#    Here: Compute the inverse Fourier transform three times:\n",
    "#    - Standard inverse Fourier transform\n",
    "#    - Inverse Fourier transform with the phase set to zero\n",
    "#    - Inverse Fourier transform with the amplitude set to one\n",
    "\n",
    "# 5) Observations?\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "<a id='exercise3'></a>\n",
    "\n",
    "## **â˜† Exercise 3: Spatial filtering with kernels**\n",
    "\n",
    "In this exercise, you'll explore how different filter kernels affect an image. Feel free to experiment by designing your own kernels and observing the results!\n",
    "\n",
    "**Note:** Kernels must have an odd number of rows and columns so that the center of the kernel aligns with a specific pixel.\n",
    "\n",
    "\n",
    "### **Instructions**\n",
    "* Check out the following resources for examples of commonly used kernels:\n",
    "  * [Wikipedia: Image processing kernels](https://en.wikipedia.org/wiki/Kernel_(image_processing))\n",
    "  * [setosa.io: Interactive kernel visualizations](https://setosa.io/ev/image-kernels/)\n",
    "* Choose a few kernels and implement them in Python.\n",
    "* Apply the kernels to the image `\"camera.png\"` using one of the following methods:\n",
    "  * OpenCV: [cv.filter2D()](https://docs.opencv.org/3.4/d4/dbd/tutorial_filter_2d.html)\n",
    "  * SciPy: [scipy.signal.convolve2d()](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.convolve2d.html)\n",
    "\n",
    "Remember that applying a filter is equivalent to convolving an image with a kernel. As discussed in the lecture, performing convolution via the Fourier domain can be more efficientâ€”particularly for large kernels. However, for small kernels (typically size < 11), direct convolution is usually faster. Functions like `cv.filter2D()` and `convolve2d()` automatically choose the appropriate method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "###    EXERCISE    ###\n",
    "######################\n",
    "\n",
    "image = cv.imread(\"../data/images/camera.png\", cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "kernel = ...\n",
    "image_filt = ... \n",
    "\n",
    "isp.show_image_pair(image, image_filt, \n",
    "                    title1=\"Original\", \n",
    "                    title2=\"Filtered\", \n",
    "                    figsize=(9, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='exercise4'></a>\n",
    "\n",
    "## **â˜† Exercise 4: Edge detection**\n",
    "\n",
    "In the previous exercise, we saw that certain kernels can be used to enhance edges in an image. These kernels approximate the derivative of the image. Common examples include the Sobel and Prewitt filters. Another widely used edge detector is the Laplacian filter.\n",
    "\n",
    "Note: Computing the derivative of an image is sensitive to noise amplification. (Can you explain why?)\n",
    "To reduce the effect of noise, it is good practice to smooth the image before computing its derivative.\n",
    "\n",
    "Edge detection is a two-step process:\n",
    "1. **Enhance the edges** by transforming the image (e.g., using a gradient or Laplacian filter).\n",
    "2. **Detect the edges** by applying a thresholding technique to produce a binary edge mask.\n",
    "\n",
    "In this exercise, we want to implement such an edge detection algorithm.\n",
    "\n",
    "### **Instructions**\n",
    "1. Load the image in grayscale.\n",
    "2. Smooth the image using cv.GaussianBlur().\n",
    "3. Choose a suitable edge-enhancing kernel.\n",
    "4. Apply thresholding to generate a binary mask that highlights the edges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "###    EXERCISE    ###\n",
    "######################\n",
    "\n",
    "# 1) Load the image \"camera.jpg\" and display it.\n",
    "image = ...\n",
    "\n",
    "# 2) Smooth the image using cv.GaussianBlur()\n",
    "image_smoothed = ...\n",
    "\n",
    "# 3) + 4) Implement your edge detection method\n",
    "...\n",
    "edges = ...\n",
    "\n",
    "# Visualization:\n",
    "isp.show_image_pair(image, edges, \n",
    "                    title1=\"Original\", \n",
    "                    title2=\"Edges\", \n",
    "                    figsize=(9, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='exercise5'></a>\n",
    "\n",
    "## **â˜† Exercise 5: Border handling**\n",
    "\n",
    "In both spectral filtering (e.g., in Exercise 1) and spatial filtering (e.g., convolution with a kernel), proper handling of image borders is essential to avoid unwanted artifacts. This section briefly illustrates how OpenCV provides convenient ways to manage image edges.\n",
    "\n",
    "In spectral filtering, artifacts often arise due to discontinuities at the image borders, especially since the Discrete Fourier Transform (DFT) assumes the image is periodic. One effective way to suppress these artifacts is to extend the image using mirrored or repeated borders.\n",
    "\n",
    "OpenCV functions such as [`cv.filter2D()`](https://docs.opencv.org/4.x/d4/d86/group__imgproc__filter.html#ga27c049795ce870216ddfb366086b5a04)   support an optional `borderType` parameter, which specifies how to handle the borders. The default is `cv.BORDER_DEFAULT`, which reflects (mirrors) the border pixels. See the full list of available options [here](https://docs.opencv.org/4.x/d2/de8/group__core__array.html#ga209f2f4869e304c82d07739337eae7c5).\n",
    "\n",
    "### **Instructions**\n",
    "* Load an arbitrary image\n",
    "* Illustrate the different border types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "###    EXERCISE    ###\n",
    "######################\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-isp-fs24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
