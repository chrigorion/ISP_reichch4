{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Live video and features**\n",
    "\n",
    "\n",
    "<div style=\"color:#777777;margin-top: -15px;\">\n",
    "<b>Author</b>: Norman Juchler |\n",
    "<b>Course</b>: ADLS ISP |\n",
    "<b>Version</b>: v1.2 <br><br>\n",
    "<!-- v1.2, 23.04.2025: Refactored text -->\n",
    "</div>\n",
    "\n",
    "In this notebook, we'll take a closer look at detecting features in images – specific points or patterns that are informative and distinct, such as corners, edges, or blobs. These features are often used in tasks like image matching, motion tracking, or object recognition.\n",
    "\n",
    "We'll focus on corner detection and edge detection, which are two fundamental approaches to identifying such features. To make the tutorial a bit more fun and interactive, we'll apply these techniques in real time using a live video feed from your webcam.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Preparations**\n",
    "\n",
    "The usual preparations... The package `isp` provides some helper functions to easily render images in this Jupyter notebook.\n",
    "\n",
    "To access certain advanced features, we need to make sure that the opencv-contrib-python package is installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.fft\n",
    "import scipy.signal\n",
    "\n",
    "# We need to install the OpenCV contrib package for some \n",
    "# advanced features (SIFT and SURF algorithms)\n",
    "if not hasattr(cv, \"xfeatures2d\"):\n",
    "    !pip install opencv_contrib_python\n",
    "    # Import the package again\n",
    "    import importlib\n",
    "    iportlib.reload(cv)\n",
    "\n",
    "# Enable vectorized output (for nicer plots)\n",
    "%config InlineBackend.figure_formats = [\"svg\"]\n",
    "\n",
    "# Inline backend configuration\n",
    "%matplotlib inline\n",
    "\n",
    "# Functionality related to this course\n",
    "sys.path.append(\"..\")\n",
    "import isp\n",
    "\n",
    "# Jupyter / IPython configuration:\n",
    "# Automatically reload modules when modified\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exercise 1: Streaming a live video with OpenCV**\n",
    "\n",
    "Displaying a live video stream from your webcam is fairly straightforward using OpenCV. To access and display a webcam video, we:\n",
    "* Create a `cv.VideoCapture()` object to access the camera.\n",
    "* Continuously read frames from the stream.\n",
    "* Display each frame using a suitable method.\n",
    "\n",
    "**Display the video:** Two approaches are shown below: one using `cv.imshow()` in a native window, and one for Jupyter notebooks using a *multithreaded* setup.\n",
    "\n",
    "* Option 1: Display in a native window using `cv.imshow()`. This is the simplest way to display frames. It opens a separate window that updates with each new frame.\n",
    "* Option 2: Display real-time video directly inside a Jupyter notebook. This is a bit more complex, as it requires a multithreaded setup*: One thread captures frames from the webcam. Another thread updates the display in the notebook. This approach gives us more flexibility, but is more sensitive to environment-specific limitations.\n",
    "\n",
    "**Camera selection**: With the parameter `cam_id`, you can select which camera to use: 0 usually refers to the built-in webcam. 1 or higher refers to external or virtual cameras.\n",
    "\n",
    "Accessing hardware devices such as cameras may not work in all Jupyter environments. This depends on system drivers and low-level access, which may be restricted. If you encounter problems, let me know or try running the script in a standalone Python environment instead.\n",
    "\n",
    "\n",
    "### **Instructions:**\n",
    "\n",
    "Read the following two examples and try whether your webcam works for real-time image processing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Example 1: Display the video in a separate window**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_camera_cv(cam_id, \n",
    "                  window_name=\"Webcam\", \n",
    "                  show_ontop=True,\n",
    "                  width=640,\n",
    "                  height=480,\n",
    "                  flip=False, \n",
    "                  func=None, \n",
    "                  **kwargs):\n",
    "    \"\"\"Run a camera feed and display it using OpenCV.\n",
    "\n",
    "    Args:\n",
    "        cam_id (int): Camera ID (usually 0).\n",
    "        window_name (str): Name of the window.\n",
    "        width (int): Width of the window.\n",
    "        height (int): Height of the window.\n",
    "        flip (bool): Flip the image horizontally.\n",
    "        func (function): Function to apply to the image.\n",
    "        **kwargs: Keyword arguments for the function.\n",
    "    \"\"\"\n",
    "\n",
    "    cap = cv.VideoCapture(cam_id)\n",
    "\n",
    "    # Adjust the camera settings (may work, or not)\n",
    "    cap.set(cv.CAP_PROP_FRAME_WIDTH, width)  # adjust width\n",
    "    cap.set(cv.CAP_PROP_FRAME_HEIGHT, height)  # adjust height\n",
    "\n",
    "    # Create named window\n",
    "    cv.namedWindow(window_name, cv.WINDOW_AUTOSIZE)\n",
    "    # Make the window always on top\n",
    "    if show_ontop:\n",
    "        cv.setWindowProperty(window_name, cv.WND_PROP_TOPMOST, 1)\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            # Read image from capturing device\n",
    "            success, img = cap.read()\n",
    "            if not success:\n",
    "                break\n",
    "            if flip:\n",
    "                img = cv.flip(img, 1)\n",
    "            if func is not None:\n",
    "                # Modify image using the provided function\n",
    "                img = func(img, **kwargs)\n",
    "            # Display the image in the named window\n",
    "            cv.imshow(window_name, img)\n",
    "            # Wait and fetch for key input (the above window should be selected)\n",
    "            key = cv.waitKey(1) & 0xFF\n",
    "            # Quit if \"q\" or \"Q\" is pressed.\n",
    "            if key in (ord(\"q\"), ord(\"Q\")): \n",
    "                cap.release()\n",
    "                break\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    finally:\n",
    "        # We should always release the camera\n",
    "        cap.release()\n",
    "        # Comment out the following lines if you want to keep the window open\n",
    "        cv.destroyAllWindows() \n",
    "        cv.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# Run demo\n",
    "####################\n",
    "\n",
    "# Choose the camera\n",
    "cam_id = 0\n",
    "\n",
    "# Window name\n",
    "window_name = \"Live Video\"\n",
    "\n",
    "# Flip the image\n",
    "flip = True\n",
    "\n",
    "# Run the camera!\n",
    "run_camera_cv(cam_id, \n",
    "              window_name=window_name, \n",
    "              flip=flip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Example 2: Display the video directly within the Jupyter notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_camera_jupyter(cam_id=0, \n",
    "                       width=640,\n",
    "                       height=480, \n",
    "                       frame_rate=0.1,\n",
    "                       keep_last_frame=False,\n",
    "                       func=None, \n",
    "                       **kwargs):\n",
    "    \"\"\"Run a camera feed and display it within Jupyter.\n",
    "    \n",
    "    It's nice to use this function with a Jupyter notebook, but it may be slow.\n",
    "\n",
    "    Args: \n",
    "        cam_id: Camera ID (usually 0)\n",
    "        width: Width of the image\n",
    "        height: Height of the image\n",
    "        frame_rate: Frame rate in frames per second\n",
    "        keep_last_frame: Keep the last frame when stopping the camera\n",
    "        func: Function to apply to the frame\n",
    "        kwargs: Keyword arguments to pass to the function\n",
    "    \"\"\"\n",
    "\n",
    "    from IPython.display import display, Image\n",
    "    import ipywidgets as widgets\n",
    "    import threading\n",
    "\n",
    "    # Set up the stop button.\n",
    "    stopButton = widgets.ToggleButton(\n",
    "        value=False,\n",
    "        description=\"Stop camera\",\n",
    "        disabled=False,\n",
    "        button_style=\"info\",  # 'success', 'info', 'warning', 'danger' or ''\n",
    "        tooltip=\"Stop camera\",\n",
    "        icon=\"camera-retro\",  # (FontAwesome names without the `fa-` prefix)\n",
    "        #style=dict(font_weight=\"bold\",)\n",
    "    )\n",
    "\n",
    "    # Display function\n",
    "    import time\n",
    "    def view(button):\n",
    "        cap = cv.VideoCapture(cam_id)\n",
    "        cap.set(cv.CAP_PROP_FRAME_WIDTH, width) # adjust width\n",
    "        cap.set(cv.CAP_PROP_FRAME_HEIGHT, height) # adjust height\n",
    "        \n",
    "        display_handle=display(None, display_id=True)\n",
    "        while True:\n",
    "            _, frame = cap.read()\n",
    "            frame = cv.flip(frame, 1) # if your camera reverses your image\n",
    "            time.sleep(1/frame_rate)\n",
    "            if frame is not None and frame.size != 0:\n",
    "                if func is not None:\n",
    "                    frame = func(frame, **kwargs)\n",
    "                _, frame = cv.imencode(\".jpeg\", frame)\n",
    "                image = Image(data=frame.tobytes(),\n",
    "                              width=width, height=height)\n",
    "                display_handle.update(image)\n",
    "            if stopButton.value==True:\n",
    "                print(\"Stopping video stream...\")\n",
    "                cap.release()\n",
    "                if not keep_last_frame:\n",
    "                    # Erase last frame\n",
    "                    display_handle.update(None)\n",
    "                    # Hide button\n",
    "                    button.layout.visibility = \"hidden\"\n",
    "                break\n",
    "                \n",
    "    # Run\n",
    "    display(stopButton);\n",
    "    thread = threading.Thread(target=view, args=(stopButton,));\n",
    "    thread.start();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "####################\n",
    "# Settings\n",
    "####################\n",
    "\n",
    "# Choose the camera\n",
    "cam_id = 0\n",
    "\n",
    "# Jupyter cannot process too many frames per second...\n",
    "frame_rate = 10\n",
    "\n",
    "# Adjust width and height. Use None for screen-width\n",
    "width = 800\n",
    "#height = None\n",
    "\n",
    "# Keep last frame alive\n",
    "keep_last_frame = False\n",
    "\n",
    "run_camera_jupyter(cam_id, \n",
    "                   width=width, \n",
    "                   frame_rate=frame_rate, \n",
    "                   keep_last_frame=keep_last_frame);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Using these functions, we can stream image frames from the camera and process them in real time.\n",
    "\n",
    "To manipulate the video stream, you can provide a custom function via the `func` argument. This function should take a single frame as input and return the modified frame as output. Additional parameters for the function can be passed through the `kwargs` dictionary. Below is an example of a simple function that applies a blur filter to each frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur(img, kernel_size=5):\n",
    "    \"\"\"Blur an image using a Gaussian filter.\n",
    "    \"\"\"\n",
    "    return cv.GaussianBlur(img, (kernel_size, kernel_size), 0) \n",
    "\n",
    "cam_id = 0\n",
    "run_camera_cv(cam_id, \n",
    "              window_name=\"Demo: Blur\",\n",
    "              func=blur, kernel_size=105)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can compute the amplitude spectrum of the image..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft(img):\n",
    "    \"\"\"Compute the FFT of an image.\n",
    "    \"\"\"\n",
    "    # Convert to grayscale\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    # Compute the FFT\n",
    "    ft = scipy.fft.fft2(gray)\n",
    "    ft = np.fft.fftshift(ft)\n",
    "    ft_mag = np.log(np.abs(ft)+1)\n",
    "    # ft_mag is float64. Normalize the image to [0,1]\n",
    "    if ft_mag.max() > 0:\n",
    "        ft_mag = ft_mag/ft_mag.max()\n",
    "    #ft_mag = cv.normalize(ft_mag, None, 0, 1, cv.NORM_MINMAX)\n",
    "    return ft_mag\n",
    "\n",
    "\n",
    "run_camera_cv(cam_id, \n",
    "              window_name=\"Demo: Amplitude spectrum\",\n",
    "              func=fft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='exercise2'></a>\n",
    "\n",
    "## **☆ Exercise 2: Canny edge detector**\n",
    "\n",
    "In the previous notebook, you explored how to detect edges using the Canny edge detector. In this exercise, you'll apply the same technique to a live video stream from the camera.\n",
    "\n",
    "### **Instructions:**\n",
    "\n",
    "Adapt the demo code above to apply Canny edge detection to each frame of the webcam feed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "###    EXERCISE    ###\n",
    "######################\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='exercise3'></a>\n",
    "\n",
    "## **☆ Exercise 3: Corner and blob features**\n",
    "\n",
    "Corner and blob features are specific, easily recognizable points or regions in an image where the local appearance is distinct — for example, corners, junctions, or round blobs. These features are often used as keypoints for tracking, matching, or object recognition.\n",
    "\n",
    "OpenCV provides a wide range of feature detectors, including both traditional and more advanced algorithms. In the lecture, we discussed the Scale-Invariant Feature Transform (SIFT), but there are also others such as the Harris corner detector, the Shi-Tomasi detector, the FAST detector, and more. The good news: OpenCV includes implementations of all of them, and their usage is quite similar.\n",
    "\n",
    "### **Instructions:**\n",
    "\n",
    "- Skim through the following overview of feature detection algorithms available in OpenCV: [Feature detection and description](https://docs.opencv.org/4.x/db/d27/tutorial_py_table_of_contents_feature2d.html)\n",
    "- Try out at least two different feature detectors and visualize their output using your webcam. If your webcam is not available, you can use a sample image from `../data/images`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "###    EXERCISE    ###\n",
    "######################\n",
    "\n",
    "def harris_corner(img, block_size=5, ksize=3, k=0.14):\n",
    "    ...\n",
    "    img = ...\n",
    "    return img\n",
    "\n",
    "run_camera_cv(cam_id=0,\n",
    "              window_name=\"Harris corner detection\",\n",
    "              func=harris_corner)\n",
    "\n",
    "\n",
    "...\n",
    "...\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-isp-fs24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
