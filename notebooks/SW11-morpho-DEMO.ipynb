{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Morphological operations**\n",
    "\n",
    "<div style=\"color:#777777;margin-top: -15px;\">\n",
    "<b>Author</b>: Norman Juchler |\n",
    "<b>Course</b>: ADLS ISP |\n",
    "<b>Version</b>: v1.2 <br><br>\n",
    "<!-- Date: 06.05.2025 -->\n",
    "<!-- Comments: Entirely refactored -->\n",
    "</div>\n",
    "\n",
    "In this notebook, we demonstrate the effects of morphological operations on images.\n",
    "\n",
    "Morphological operations are fundamental image processing techniques that analyze and modify images based on their shapes. Each operation requires two inputs: an image and a *structuring element*. The structuring element is typically a small binary matrix that defines the neighborhood used to process each pixel in the input image. It determines the shape and extent of the operation being applied. The illustration below shows several commonly used structuring elements.\n",
    "\n",
    "\n",
    "![Common structuring elements](../data/doc/structuring-elements-2d.svg)  \n",
    "**Figure 1**: Common structuring elements.\n",
    "\n",
    "Similar to the kernels in a convolution, the structuring element is swept across the input image. However, the operations performed are different: instead of multiplying and summing pixel values, morphological operations are based on set theory and logical operations such as *intersection*, *union*, and *complement*.\n",
    "\n",
    "For instance, the **erosion** operation (see below) computes the intersection of the image and the shifted structuring element: Only if all foreground pixels (value = 1) in the structuring element at a given position overlap with foreground pixels in the input image, the output pixel is set to 1 at that position. See Figure 2. \n",
    "\n",
    "Likewise, the **dilation** operation computes the union of the image and the shifted structuring element: If at least one foreground pixel in the structuring element overlaps with a foreground pixel in the input image, the output pixel is set to 1. See Figure 3.\n",
    "\n",
    "\n",
    "![Binary erosion](../data/doc/binary-erosion.svg)  \n",
    "**Figure 2**: Binary erosion of an input image (1) using a circular structuring element (2). Subfigures (3) and (4) show the result.\n",
    "\n",
    "![Binary dilation](../data/doc/binary-dilation.svg)  \n",
    "**Figure 3**: Binary dilation of an input image (1) using a circular structuring element (2). Subfigures (3) and (4) show the result.\n",
    "\n",
    "Morphological operations are used for various image processing tasks, such as noise removal, object isolation, and feature enhancement. In this notebook, we will cover four basic operations: erosion, dilation, opening, and closing.  \n",
    "Instead of providing formal definitions, we will explore their behavior through examples.\n",
    "\n",
    "Credits: This notebook follows a tutorial from PyImageSearch, written by Adrian Rosebrock. [Link](https://pyimagesearch.com/2021/04/28/opencv-morphological-operations/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Preparations**\n",
    "\n",
    "The usual preparations... The package `isp` provides some helper functions to easily render images in this Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Enable vectorized output (for nicer plots)\n",
    "%config InlineBackend.figure_formats = [\"svg\"]\n",
    "\n",
    "# Inline backend configuration\n",
    "%matplotlib inline\n",
    "\n",
    "# Functionality related to this course\n",
    "sys.path.append(\"..\")\n",
    "import isp\n",
    "\n",
    "# Jupyter / IPython configuration:\n",
    "# Automatically reload modules when modified\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Examplary image data**\n",
    "\n",
    "In the following, we use a binary image containing some text and deliberately add noise to it.\n",
    "\n",
    "A binary image contains only two possible values per pixel. Depending on the data type, these are typically 0 and 1 (dtype=bool), or 0 and 255 (dtype=np.uint8). Since OpenCV’s morphological operations expect images of type np.uint8, we will use this representation. In this format, pixels with the higher value are typically referred to as the **foreground**, while those with the lower value represent the **background**.\n",
    "\n",
    "Note that the morphological operations can also be applied to grayscale and even color images, but for now let's assume binary images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_border(w, h, margin, inside=False):\n",
    "    while True:\n",
    "        x = np.random.randint(0, w)\n",
    "        y = np.random.randint(0, h)\n",
    "        is_valid = ((x < margin) or (x >= (w - margin)) \n",
    "                    or (y < margin) or (y >= h - margin))\n",
    "        if inside:\n",
    "            is_valid = not is_valid\n",
    "        if is_valid:\n",
    "            return x, y\n",
    "\n",
    "# Read in the image and invert it\n",
    "img = cv.imread(\"../data/images/word-ice-cream.png\", cv.IMREAD_GRAYSCALE)\n",
    "img = 255 - img\n",
    "\n",
    "# Add dots of noise such that they do not overlap with the text.\n",
    "h, w = img.shape\n",
    "img_noisy_w = img.copy()  # Image with white spots\n",
    "img_noisy_b = img.copy()  # Image with black spots\n",
    "np.random.seed(1)\n",
    "for i in range(50):\n",
    "    x, y = sample_border(w, h, 20)\n",
    "    r = np.random.randint(1, 4)\n",
    "    cv.circle(img_noisy_w, (x, y), r, 255, -1, lineType=cv.LINE_AA)\n",
    "for i in range(400):\n",
    "    x, y = sample_border(w, h, 20, inside=True)\n",
    "    cv.circle(img_noisy_b, (x, y), 1, 0, -1, lineType=cv.LINE_AA)\n",
    "\n",
    "# Display the image\n",
    "isp.show_image_chain([img, img_noisy_w, img_noisy_b], \n",
    "                     titles=[\"Input image\", \n",
    "                             \"Image with white spots\", \n",
    "                             \"Image with black spots\"], \n",
    "                     suppress_info=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Erosion**\n",
    "\n",
    "As the name suggests, erosion reduces or \"erodes\" the foreground regions in an image. It is useful for removing small blobs or noise, and for thinning visible structures.\n",
    "\n",
    "Erosion works by defining a structuring element and sliding it across the input image from left to right and top to bottom. A foreground pixel in the output image is retained only if all corresponding pixels under the structuring element are greater than 0. Otherwise, the pixel is set to 0 (background). For grayscale images, the minimum value under the structuring element is used instead of applying a binary condition.\n",
    "\n",
    "Note how the small white spots are removed by erosion, and how the text appears thinner after the operation.\n",
    "\n",
    "In OpenCV, we can specify our own structuring element (SE), or use the default one (a 3×3 square). The SE defines the shape and size of the neighborhood that must completely fit within the foreground region for a pixel to remain in the output during erosion. A circular SE tends to produce rounded contours, while a square SE helps preserve corners and straight edges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can specify our own structuring element (SE),\n",
    "# or use the default one (a 3×3 square).\n",
    "#se = np.ones((5, 5), np.uint8)\n",
    "se = None\n",
    "\n",
    "results = {}\n",
    "results[\"Original\"] = img_noisy_w\n",
    "for i in range(1, 4):\n",
    "    result = cv.erode(img_noisy_w, se, iterations=i)\n",
    "    results[f\"Eroded ({i} iterations)\"] = result\n",
    "    \n",
    "isp.show_image_grid(results, suppress_info=True, ncols=1, figsize=(6, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Dilation**\n",
    "\n",
    "Dilation is the opposite to erosion. Instead of shrinking the foreground, dilation expands the boundaries of foreground objects in an image. It increases the size of foreground regions and is particularly useful for connecting broken components or filling small gaps.\n",
    "\n",
    "Like erosion, dilation uses a structuring element (also called a kernel). A pixel in the output image is set to white (> 0) if at least one corresponding pixel under the structuring element is greater than zero. (For grayscale input images, the maximum value within the structuring element's neighborhood is taken.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se = None  # Default structuring element, but you can specify your own\n",
    "results = {}\n",
    "results[\"Original\"] = img_noisy_b\n",
    "for i in range(1, 4):\n",
    "    results[f\"Dilated ({i} iterations)\"] = cv.dilate(img_noisy_b, se, iterations=i)\n",
    "    \n",
    "isp.show_image_grid(results, suppress_info=True, ncols=1, figsize=(6, 7));\n",
    "#isp.save_figure(path=\"morpho-dilation.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that erosion and dilation are dual operations under image complementation: applying erosion to the inverted image is equivalent to applying dilation to the original image, and vice versa (as long as the structuring element is symmetric). The following code illustrates this behavior:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se = np.ones((5, 5), np.uint8)\n",
    "img_dilated = cv.dilate(img, se, iterations=1)\n",
    "img_eroded = 255 - cv.erode(255-img, se, iterations=1)\n",
    "img_diff = img_dilated - img_eroded\n",
    "print(\"Test: The difference between dilated image and eroded complement of the image should be zero:\")\n",
    "print(\"      Measured difference = %d\" % np.abs(img_diff).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Opening**\n",
    "\n",
    "An opening is an erosion followed by a dilation.\n",
    "\n",
    "This operation is useful for removing small white blobs (noise) from an image while preserving the overall shape of larger objects. The erosion step eliminates small blobs and thins the structures, and the dilation step regrows the remaining regions to their original size.\n",
    "\n",
    "In this example, we construct our own structuring element. OpenCV also provides a convenient function to create structuring elements: `cv.getStructuringElement(shape, ksize)`, where `type` can be one of `cv.MORPH_RECT`, `cv.MORPH_CROSS`, `cv.MORPH_ELLIPSE`; and `ksize` defines the size of the structuring element (kernel) in pixels. A structuring element is similar to a convolution kernel, but it is used in morphological operations, which follow different logical rules than standard convolutions.\n",
    "\n",
    "Notice how the opening operation removes small white spots from the image. Larger kernels remove larger spots, but may also break thin parts of objects. Choosing the right kernel shape and size is crucial for the desired effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [(3, 3), (5, 5), (7, 7)]\n",
    "results = {}\n",
    "results[\"Original\"] = img_noisy_w\n",
    "for i, size in enumerate(sizes):\n",
    "    # Construct a rectangular structuring elmenet from the \n",
    "    # current size and then apply an \"opening\" operation\n",
    "    se = cv.getStructuringElement(cv.MORPH_ELLIPSE, size)\n",
    "    ret = cv.morphologyEx(img_noisy_w, cv.MORPH_OPEN, se, iterations=1)\n",
    "    results[\"Opening (structuring element: %dx%d)\" % size] = ret\n",
    "    \n",
    "isp.show_image_grid(results, suppress_info=True, ncols=1, figsize=(6, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Closing**\n",
    "\n",
    "The closing operation is the opposite of opening: it consists of a dilation followed by an erosion.\n",
    "\n",
    "As the name suggests, closing is used to *fill small holes* inside objects or to *connect nearby components*. The dilation step expands object boundaries, closing gaps or holes, and the erosion step then restores the original size while preserving the closure.\n",
    "\n",
    "We can use the same code as for opening – only the type of morphological operation needs to be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [(3, 3), (5, 5), (7, 7)]\n",
    "results = {}\n",
    "results[\"Original\"] = img_noisy_b\n",
    "for size in sizes:\n",
    "    # Construct a rectangular structuring elmenet from the \n",
    "    # current size and then apply an \"opening\" operation\n",
    "    se = cv.getStructuringElement(cv.MORPH_ELLIPSE, size)\n",
    "    ret = cv.morphologyEx(img_noisy_b, cv.MORPH_CLOSE, se, iterations=1)\n",
    "    results[\"Closing (structuring element: %dx%d)\" % size] = ret\n",
    "    \n",
    "isp.show_image_grid(results, suppress_info=True, ncols=1, figsize=(6, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Morphological gradient**\n",
    "\n",
    "A morphological gradient is the difference between a dilation and an erosion of an image. It highlights the boundaries of objects and is useful for detecting edges or outlines in binary (or grayscale) images.\n",
    "\n",
    "Again, we can use the same code structure from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [(3, 3), (5, 5), (7, 7)]\n",
    "results = {}\n",
    "results[\"Original\"] = img\n",
    "for size in sizes:\n",
    "    # Construct a rectangular structuring element from the \n",
    "    # current size and then apply an \"opening\" operation\n",
    "    se = cv.getStructuringElement(cv.MORPH_RECT, size)\n",
    "    ret = cv.morphologyEx(img, cv.MORPH_GRADIENT, se, iterations=1)\n",
    "    results[\"Gradient (structuring element: %dx%d)\" % size] = ret\n",
    "    \n",
    "isp.show_image_grid(results, suppress_info=True, ncols=1, figsize=(6, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Morphological operations and grayscale images**\n",
    "\n",
    "So far, we have applied morphological operations only to binary images. However, these operations are also defined for grayscale images (and even for color images, with some modifications).\n",
    "\n",
    "Let's take a look at a brain MRI image to see how morphological operations behave in the grayscale domain. (Source: [Radiopaedia](https://radiopaedia.org/cases/normal-brain-mri-6))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_mri = cv.imread(\"../data/images/brain-mri/brain-mri-a-t2-dark.jpg\", cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "size = (3, 3)\n",
    "se = cv.getStructuringElement(cv.MORPH_RECT, size)\n",
    "erode = cv.morphologyEx(img_mri, cv.MORPH_ERODE, se, iterations=5)\n",
    "dilate = cv.morphologyEx(img_mri, cv.MORPH_DILATE, se, iterations=5)\n",
    "opening = cv.morphologyEx(img_mri, cv.MORPH_OPEN, se, iterations=5)\n",
    "closing = cv.morphologyEx(img_mri, cv.MORPH_CLOSE, se, iterations=5)\n",
    "gradient = cv.morphologyEx(img_mri, cv.MORPH_GRADIENT, se, iterations=3)\n",
    "\n",
    "size = (11, 11)\n",
    "se = cv.getStructuringElement(cv.MORPH_RECT, size)\n",
    "tophat = cv.morphologyEx(img_mri, cv.MORPH_TOPHAT, se, iterations=1)\n",
    "\n",
    "size = (25, 25)\n",
    "se = cv.getStructuringElement(cv.MORPH_RECT, size)\n",
    "blackhat = cv.morphologyEx(img_mri, cv.MORPH_BLACKHAT, se, iterations=1)\n",
    "\n",
    "results = {\n",
    "    \"Original\": img_mri,\n",
    "    \"Erosion\": erode,\n",
    "    \"Dilation\": dilate,\n",
    "    \"Opening\": opening,\n",
    "    \"Closing\": closing,\n",
    "    \"Gradient\": gradient,\n",
    "    \"Top-hat\": tophat,\n",
    "    \"Black-hat\": blackhat\n",
    "}\n",
    "\n",
    "isp.show_image_grid(results, suppress_info=True, ncols=3, figsize=(9, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Top-hat (white-hat) and bottom-hat (black-hat)**\n",
    "\n",
    "Both the top-hat (white-hat) and bottom-hat (black-hat) operators are generally more suitable for grayscale images than for binary ones.\n",
    "\n",
    "A top-hat (also known as white-hat) operation is defined as the difference between the original grayscale (or single-channel) image and its opening.\n",
    "\n",
    "The top-hat operation is used to reveal bright regions in an image with a dark background, assuming that these regions are smaller than the structuring element. In contrast, the black-hat operation highlights dark regions on a bright background. These operations are only effective when the structures of interest differ significantly in size from the structuring element.\n",
    "\n",
    "A common application of the top-hat operation is the correction of uneven illumination and the enhancement of specific structures in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = img_mri.shape\n",
    "x, y = np.meshgrid(np.arange(w), np.arange(h))\n",
    "gradient = (x - w//2)**2 + (y - h//2)**2\n",
    "gradient = gradient / gradient.max()\n",
    "gradient = (gradient * 200).astype(np.uint8)\n",
    "img_dist = (img_mri//2 + gradient//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image with a continuous gradient from black to white\n",
    "gradient = np.ones_like(img)\n",
    "gradient = np.cumsum(gradient)\n",
    "\n",
    "sizes = []\n",
    "sizes.append((3,11))\n",
    "sizes.append((11,3))\n",
    "sizes.append((50,100))\n",
    "results = {}\n",
    "results[\"Original\"] = img_mri\n",
    "results[\"Distorted\"] = img_dist\n",
    "results[\"Dummy\"] = None  # Placeholder (just for visualization)\n",
    "for size in sizes:\n",
    "    se = cv.getStructuringElement(cv.MORPH_RECT, size)\n",
    "    ret = cv.morphologyEx(img_dist, cv.MORPH_TOPHAT, se, iterations=1)\n",
    "    label = \"Top-hat (kernel: %dx%d)\" % size\n",
    "    results[label] = ret\n",
    "\n",
    "isp.show_image_grid(results, suppress_info=True, ncols=3, figsize=(9, 7));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-isp-fs24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
